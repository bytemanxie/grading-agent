# Grading Agent

AI-powered exam paper recognition and answer recognition service built with NestJS and LangChain.

## Features

- ğŸ¯ Recognize question regions from exam paper images
- ğŸ“Š Support multiple question types: choice (é€‰æ‹©é¢˜), fill (å¡«ç©ºé¢˜), essay (è§£ç­”é¢˜)
- ğŸ“ Return percentage-based coordinates (0-100) for each region
- ğŸ”„ REST API for easy integration
- ğŸ“ TypeScript with full type safety
- ğŸ“š Swagger API documentation
- ğŸš€ Built with NestJS for high concurrency support

## Prerequisites

- Node.js 18+
- pnpm (recommended) or npm
- DashScope API Key ([Get one here](https://dashscope.console.aliyun.com/))

## Installation

1. Clone the repository:

```bash
git clone <repository-url>
cd grading-agent
```

2. Install dependencies:

```bash
pnpm install
# or
npm install
```

3. Configure environment variables:

```bash
cp .env.example .env
```

Edit `.env` and add your configuration:

```env
DASHSCOPE_API_KEY=your-api-key-here
QWEN_VL_MODEL=qwen-vl-max-latest
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
PORT=3002
NODE_ENV=development
```

## Usage

### Start the NestJS Server

```bash
# Development mode (with hot reload)
pnpm dev

# Production mode
pnpm build
pnpm start:prod
```

The server will start on `http://localhost:3002` by default.

### API Documentation

Once the server is running, visit:

- Swagger UI: `http://localhost:3002/api/docs`
- Health Check: `http://localhost:3002/health`

### API Endpoints

#### 1. Recognize Regions

**POST** `/api/recognition/regions`

Recognize question regions from an exam paper image.

**Request Body:**

```json
{
  "imageUrl": "https://example.com/exam-paper.jpg",
  "model": "qwen-vl-max-latest" // optional
}
```

**Response:**

```json
{
  "regions": [
    {
      "type": "choice",
      "question_number": 1,
      "x_min_percent": 5.0,
      "y_min_percent": 10.0,
      "x_max_percent": 95.0,
      "y_max_percent": 30.0
    },
    {
      "type": "fill",
      "question_number": 1,
      "x_min_percent": 5.0,
      "y_min_percent": 30.0,
      "x_max_percent": 95.0,
      "y_max_percent": 60.0
    }
  ]
}
```

#### 2. Recognize Answers

**POST** `/api/recognition/answers`

Recognize answers from exam paper regions.

**Request Body:**

```json
{
  "imageUrl": "https://example.com/exam-paper.jpg",
  "regions": [
    {
      "type": "choice",
      "question_number": 1,
      "x_min_percent": 5.0,
      "y_min_percent": 10.0,
      "x_max_percent": 95.0,
      "y_max_percent": 30.0
    }
  ],
  "model": "qwen-vl-max-latest" // optional
}
```

**Response:**

```json
{
  "regions": [
    {
      "type": "choice",
      "region": {
        "type": "choice",
        "question_number": 1,
        "x_min_percent": 5.0,
        "y_min_percent": 10.0,
        "x_max_percent": 95.0,
        "y_max_percent": 30.0
      },
      "questions": [
        {
          "question_number": 1,
          "answer": "A"
        },
        {
          "question_number": 2,
          "answer": "B"
        }
      ]
    }
  ]
}
```

### Example Usage with cURL

```bash
# Recognize regions
curl -X POST http://localhost:3002/api/recognition/regions \
  -H "Content-Type: application/json" \
  -d '{
    "imageUrl": "https://example.com/exam-paper.jpg"
  }'

# Recognize answers
curl -X POST http://localhost:3002/api/recognition/answers \
  -H "Content-Type: application/json" \
  -d '{
    "imageUrl": "https://example.com/exam-paper.jpg",
    "regions": [
      {
        "type": "choice",
        "question_number": 1,
        "x_min_percent": 5.0,
        "y_min_percent": 10.0,
        "x_max_percent": 95.0,
        "y_max_percent": 30.0
      }
    ]
  }'
```

### Integration with dl-front

The service is integrated with dl-front. Use the recognition services:

```typescript
import {
  answerSheetRecognitionService,
  answerRecognitionService,
} from '@/services';

// Recognize regions
const regions = await answerSheetRecognitionService.recognizeRegions(
  'https://example.com/exam-paper.jpg',
);

// Recognize answers
const answers = await answerRecognitionService.recognizeAnswers(
  'https://example.com/exam-paper.jpg',
  regions.regions,
);
```

Configure the recognition API URL in dl-front:

```env
NEXT_PUBLIC_RECOGNITION_API_URL=http://localhost:3002/api
```

## Output Format

### Question Types

- `choice`: Multiple choice questions (é€‰æ‹©é¢˜)
- `fill`: Fill-in-the-blank questions (å¡«ç©ºé¢˜)
- `essay`: Essay/solution questions (è§£ç­”é¢˜)

### Coordinates

All coordinates are percentages (0-100) relative to the image dimensions:

- `x_min_percent`: Left boundary
- `y_min_percent`: Top boundary
- `x_max_percent`: Right boundary
- `y_max_percent`: Bottom boundary

## Development

### Build

```bash
pnpm build
```

### Type Check

```bash
pnpm type-check
```

### Lint

```bash
pnpm lint
```

### Format

```bash
pnpm format
```

## Project Structure

```
grading-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                    # NestJS application entry
â”‚   â”œâ”€â”€ app.module.ts              # Root module
â”‚   â”œâ”€â”€ config/                    # Configuration
â”‚   â”‚   â””â”€â”€ configuration.ts
â”‚   â”œâ”€â”€ common/                    # Common utilities
â”‚   â”‚   â”œâ”€â”€ filters/              # Exception filters
â”‚   â”‚   â””â”€â”€ interceptors/        # Interceptors
â”‚   â”œâ”€â”€ recognition/               # Recognition module
â”‚   â”‚   â”œâ”€â”€ recognition.module.ts
â”‚   â”‚   â”œâ”€â”€ recognition.controller.ts
â”‚   â”‚   â”œâ”€â”€ recognition.service.ts
â”‚   â”‚   â”œâ”€â”€ dto/                  # Data Transfer Objects
â”‚   â”‚   â””â”€â”€ responses/            # Response types
â”‚   â”œâ”€â”€ services/                  # Core services
â”‚   â”‚   â”œâ”€â”€ qwen-vl.service.ts
â”‚   â”‚   â”œâ”€â”€ answer-recognition.service.ts
â”‚   â”‚   â””â”€â”€ image-crop.service.ts
â”‚   â”œâ”€â”€ types/                    # Type definitions
â”‚   â”‚   â”œâ”€â”€ region.ts
â”‚   â”‚   â””â”€â”€ answer.ts
â”‚   â””â”€â”€ index.ts                  # CLI entry (legacy)
â”œâ”€â”€ .env.example                  # Environment variables template
â”œâ”€â”€ nest-cli.json                 # NestJS CLI configuration
â”œâ”€â”€ package.json                   # Dependencies and scripts
â”œâ”€â”€ tsconfig.json                 # TypeScript configuration
â””â”€â”€ README.md                     # This file
```

## Configuration

### Environment Variables

- `DASHSCOPE_API_KEY` (required): Your DashScope API key
- `QWEN_VL_MODEL` (optional): Model name (default: `qwen-vl-max-latest`)
  - Available models:
    - `qwen-vl-max-latest`: Qwen VL Max (è¶…å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæ¨è)
    - `qwen-vl-plus-latest`: Qwen VL Plus (å¢å¼ºç‰ˆ)
    - `qwen3-vl-plus`: Qwen3 VL Plus (æœ€æ–°ç‰ˆæœ¬)
- `DASHSCOPE_BASE_URL` (optional): API base URL (default: `https://dashscope.aliyuncs.com/compatible-mode/v1`)
- `PORT` (optional): Server port (default: `3002`)
- `NODE_ENV` (optional): Environment (default: `development`)

## Architecture

The application follows NestJS best practices:

- **Modular Architecture**: Each feature is organized in its own module
- **Dependency Injection**: Services are injected using NestJS DI container
- **DTO Validation**: Request validation using class-validator
- **Error Handling**: Global exception filter for consistent error responses
- **Logging**: Request/response logging with NestJS Logger
- **API Documentation**: Swagger/OpenAPI integration

## License

MIT
